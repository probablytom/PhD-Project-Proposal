\include{preamble}
\title{Anthropomorphic Algorithms for AI Safety}
\author[Tom Wallis]{\href{http://tom.coffee}{Tom Wallis}}
\date{}

\begin{document}

\maketitle

\section{Anthopomorphic algorithms}
\smallcaps{For a long time}, sociotechnical systems analysis within computing science has been developing formalisms of human-like traits, such as trust and comfort. These allow an intelligent agent to interact with other agents in its environment in measured, cautious ways; they might be used, for example, to decide whether it should accept information from another agent if its behaviour is becoming erratic (or to discard previous data which is no longer "trustworthy"). \par

These anthopomorphic algorithms are undergoing continual improvement\cite{Kramdi}\cite{Urbano2014}, but two problems remain untouched:
\begin{enumerate}
    \item Various different anthropmorphic algorithms have been developed, but none have been combined into a system with several traits. {\newline}For example, an algorithm might be designed where an agent's ratings of trust and comfort in a given scenario influence each other --- not unlike a human's lack of trust in an agent making it less comfortable with certain situations.
    \item Lots of philosophical questions arise when developing anthopomorphic agents. There are questions in roboethics, such as the morality of creating an intelligent agent which might exhibit racial bias after its training. There are also questions in machine ethics, involving ethical decisions that an agent might make, and how they can be affected by trust and comfort.
\end{enumerate}

\section{Implications and work for Intelligent Agents}


\section{My suitability}


\nobibliography{biblio}
\bibliographystyle{plainnat}

\end{document}
